{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Geneformer & UCE for cell-type classification\n",
    "\n",
    "Run this notebook on google colab to use a free GPU! \n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/helicalAI/helical/blob/main/examples/notebooks/Geneformer-vs-UCE.ipynb)\n",
    "\n",
    "One known downstream application of RNA foundation models is cell-type classification. However, it is not always easy to know which foundation model will perform best and working with different bio foundation models is time consuming. With the Helical package, we have streamlined this task and made foundation models interchangaeble.\n",
    "\n",
    "In the example notebook, we levarge Helical to compare two leading RNA foundation models: Geneformer and UCE. We show you how to use these models for classifying cell types and evaluate them on a labelled data set.\n",
    "It also serves a template on to use those models in a standardised way in your own applications.\n",
    "\n",
    "### Geneformer\n",
    "Geneformer is a foundation transformer model pretrained on Genecorpus-30M, a corpus comprised of ~30 million single cell transcriptomes from a broad range of human tissues. Each single cellâ€™s transcriptome is presented to the model as a rank value encoding where genes are ranked by their expression in that cell normalized by their expression across the entire Genecorpus-30M. Geneformer displays both zero-shot capabilities as well as fine-tuning tasks relevant to chromatin and network dynamics.\n",
    "- ðŸ“„ [Paper](https://www.nature.com/articles/s41586-023-06139-9): The paper that made it into Nature!\n",
    "\n",
    "### UCE\n",
    "The Universal Cell Embedding (UCE) model creates a universal biological representation space for cells, leveraging a self-supervised learning approach on cell atlas data from diverse species (which is a key differentiator from geneformer, trained on human data). UCE creates an atlas of over 36 million cells, with more than 1,000 uniquely named cell types, from hundreds of experiments, dozens of tissues and eight species. It captures significant biological variations and enables mapping of any cell to this embedding without further model adjustments.\n",
    "- ðŸ“„ [Paper](https://www.biorxiv.org/content/10.1101/2023.11.28.568918v1)\n",
    "- ðŸ’½ [GitHub](https://github.com/snap-stanford/UCE)\n",
    "\n",
    "\n",
    "### ðŸ§¬ About Helical:\n",
    "Helical provides an open-source framework for and gathers state-of-the-art pre-trained genomics and transciptomics bio foundation models. Still work in progress, but we look forward to interacting with the community to build meaningful things. You can directly reach us:\n",
    "- support@helical-ai.com (slack-channel incoming). We answer within hours! Reach out if you have questions, ideas, improvement suggestions, colab, ...\n",
    "- [Github](https://github.com/helicalAI/helical-package/issues). On our github in the issue section \n",
    "\n",
    "\n",
    "### Before you start\n",
    "Be sure to install the Helical python package as descibed in [Installation](https://github.com/helicalAI/helical-package)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Imports \n",
    "Let's start by importing all the packages used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import helical\n",
    "except:\n",
    "    !pip install git+https://github.com/helicalAI/helical.git |tail -n 1\n",
    "    !pip install numpy==1.23.5\n",
    "    import helical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix,ConfusionMatrixDisplay\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "import pandas as pd\n",
    "import logging\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import Geneformer & UCE from the Helical package\n",
    "from helical.models.geneformer.model import Geneformer,GeneformerConfig\n",
    "from helical.models.uce.model import UCE,UCEConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Dataset loading and Splitting\n",
    "\n",
    "The data set is a subset of the human PBMC, comprising 54,760 training cells and 13,690 test cells, with 16,906 genes across 11 distinct cell types. It is great for benchmarking due to its class imbalance. We will pretend not to have labels for the main cell-type classification, but leverage the existing labels to evaluate the performance of the algorithms.\n",
    "\n",
    "The following cell checks if you already have the file in the folder. if not, it automatically downloads the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by running the command below to download the data set automatically (this could take a few seconds):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"https://helicalpackage.blob.core.windows.net/helicalpackage/data/10k_pbmcs_proc.h5ad\"\n",
    "\n",
    "# Extract the filename and download the file\n",
    "filename = url.split(\"/\")[-1]\n",
    "\n",
    "# Check if the file already exists in the current directory\n",
    "if os.path.exists(filename):\n",
    "    print(f\"Files already exist. Skipping downloads.\")\n",
    "else:\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(filename, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Downloaded {filename} successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to download {filename}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data in a train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ann_data = ad.read_h5ad(\"10k_pbmcs_proc.h5ad\")\n",
    "\n",
    "# Calculate the number of samples for train and test sets\n",
    "n_samples = ann_data.n_obs\n",
    "n_train = int(n_samples * 0.01)\n",
    "n_test = int(n_samples * 0.005)\n",
    "\n",
    "# Generate random indices for train and test sets\n",
    "np.random.seed(0)  # for reproducibility\n",
    "indices = np.random.permutation(n_samples)\n",
    "train_indices = indices[:n_train]\n",
    "test_indices = indices[n_train:n_train+n_test]\n",
    "\n",
    "# Split the data for training and evaluating down the line\n",
    "X_train = ann_data[train_indices]\n",
    "X_test = ann_data[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Zero Shot prediction with Geneformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Model training and inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time you execute the cell below, the model weights will be downloaded automatically, this could take a few seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_config = GeneformerConfig(batch_size=5,device=device)   \n",
    "geneformer = Geneformer(configurer=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The \"process_data\"-function from the Helical package pre-processes the data. \n",
    "# It takes AnnData as an input. \n",
    "# More information in our documentation\n",
    "train_dataset = geneformer.process_data(X_train, nproc=1, gene_names=\"gene_symbols\")\n",
    "test_dataset = geneformer.process_data(X_test, nproc=1, gene_names=\"gene_symbols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref_embeddings = geneformer.get_embeddings(train_dataset)\n",
    "test_embeddings = geneformer.get_embeddings(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Visualization with UMAP\n",
    "Let's visualize the embeddings leveraging UMAP. The idea is simple: can we identify clusters of cells that the models considers as being similar enough to put them close in space ? If this hypothesis happens to be true, the models can be used to infer cell types based on a few hand-labelled cells!\n",
    "\n",
    "In the cell below, we plot our outputs once without labels and onc with the labels from our dataset (which in a real-world setup would of course not be available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(min_dist=0.2, n_components=2, n_epochs=None,n_neighbors=3)\n",
    "mapper = reducer.fit(ref_embeddings)\n",
    "\n",
    "plot_df = pd.DataFrame(mapper.embedding_,columns=['px','py'])\n",
    "labels = X_train.obs['cell_type']\n",
    "plot_df['Cell Type'] = labels.values\n",
    "\n",
    "\n",
    "# Create a matplotlib figure and axes\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(14, 5))\n",
    "\n",
    "#plt.style.use(\"dark_background\")\n",
    "\n",
    "sns.scatterplot(data = plot_df,x='px',y='py',sizes=(50,200),ax=axs[0],palette=\"pastel\")\n",
    "axs[0].set_title('UMAP of Reference Data without labels')\n",
    "\n",
    "sns.scatterplot(data = plot_df,x='px',y='py',hue='Cell Type',sizes=(50,200),ax=axs[1],palette=\"pastel\")\n",
    "axs[1].set_title('UMAP of Reference Data with labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks great! Geneformer seems to be capable to cluster cells according to their cell type. Let's explore how we can leverage this capability to infer cell types on an unlabelled data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Prediction: Leverage your hand-labelled cells to predict label of other cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a K-Neirhbours classifier to predict cell types on an unlabelled data set. We have separated our data set into a train and test set. Let's use the train set to train a classifier and predict labels on the \"unseen\" test set. We can then use the labels in this test set to evaluate how accurate our prediction was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = X_train.obs['cell_type']\n",
    "neigh = KNeighborsClassifier(n_neighbors=5,metric='cosine') \n",
    "neigh.fit(ref_embeddings, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_labels = neigh.predict(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm_geneformer = confusion_matrix(X_test.obs['cell_type'],pred_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_geneformer, display_labels=neigh.classes_)\n",
    "disp.plot(xticks_rotation=\"vertical\")\n",
    "plt.title(\"Geneformer - KNN Classification\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(X_test.obs['cell_type'],pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Zero Shot prediction with UCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same with UCE so we can compare the performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and inference\n",
    "Let's load the model weights of UCE (keep in mind that UCE is a large model and downloading the weights will take approximately 10 minutes - make sure to keep your pc open during this time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_config = UCEConfig(batch_size=5)\n",
    "uce = UCE(configurer=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = uce.process_data(X_train)\n",
    "ref_embeddings = uce.get_embeddings(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization with UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(min_dist=0.2, n_components=2, n_epochs=None,n_neighbors=3)\n",
    "mapper = reducer.fit(ref_embeddings)\n",
    "\n",
    "labels = X_train.obs['cell_type']\n",
    "\n",
    "plot_df = pd.DataFrame(mapper.embedding_,columns=['px','py'])\n",
    "plot_df['Cell Type'] = labels.values\n",
    "\n",
    "# Create a matplotlib figure and axes\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(14, 5))\n",
    "\n",
    "sns.scatterplot(data = plot_df,x='px',y='py',sizes=(50,200),ax=axs[0],palette=\"pastel\")\n",
    "axs[0].set_title('UMAP of Reference Data without labels')\n",
    "\n",
    "sns.scatterplot(data = plot_df,x='px',y='py',hue='Cell Type',sizes=(50,200),ax=axs[1],palette=\"pastel\")\n",
    "axs[1].set_title('UMAP of Reference Data with labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: k-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = uce.process_data(X_test)\n",
    "test_embeddings = uce.get_embeddings(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = X_train.obs['cell_type']\n",
    "neigh = KNeighborsClassifier(n_neighbors=5,metric='cosine') \n",
    "neigh.fit(ref_embeddings, labels)\n",
    "\n",
    "pred_labels = neigh.predict(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm_UCE = confusion_matrix(X_test.obs['cell_type'],pred_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_UCE, display_labels=neigh.classes_)\n",
    "disp.plot(xticks_rotation=\"vertical\")\n",
    "plt.title(\"UCE - KNN Classification\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(X_test.obs['cell_type'],pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Compare Results - Who's better ?\n",
    "Now, who is better ? which model should you use for your cell classification task ? Let's put the results next to each other to compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a matplotlib figure and axes\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_geneformer, display_labels=neigh.classes_)\n",
    "disp.plot(xticks_rotation=\"vertical\",ax=axs[0])\n",
    "axs[0].set_title('Geneformer Confusion Matrix')\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_UCE, display_labels=neigh.classes_)\n",
    "disp.plot(xticks_rotation=\"vertical\",ax=axs[1])\n",
    "axs[1].set_title('UCE Confusion Matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close enough. \n",
    "\n",
    "Both show good performances in terms of counts. \n",
    "It would be interesting to test this on your own data and extend this script to other models (we recently have added scGPT, try it out !)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next ?\n",
    "Stay tuned, we will add the most relevant RNA foundation models to Helical (and other modalities).\n",
    "\n",
    "If you have a use case in mind that we should look at, some feedback to share, or you just want to have a chat, please reach out (support@helical-ai.com), we will get back to you really quickly :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
