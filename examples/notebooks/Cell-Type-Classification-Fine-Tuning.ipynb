{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification fine-tuning using Helical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell type classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 16:50:39.158815: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-20 16:50:39.167437: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-20 16:50:39.176838: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-20 16:50:39.179680: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-20 16:50:39.187669: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-20 16:50:39.731966: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/matthew/helical-dev/helical/helical/models/scgpt/model_dir/multiomic_model.py:19: UserWarning: flash_attn is not installed\n",
      "  warnings.warn(\"flash_attn is not installed\")\n"
     ]
    }
   ],
   "source": [
    "from helical.models.geneformer.geneformer_config import GeneformerConfig\n",
    "from helical.models.geneformer.fine_tuning_model import GeneformerFineTuningModel\n",
    "from helical.models.geneformer.model import Geneformer\n",
    "from helical.models.scgpt.fine_tuning_model import scGPTFineTuningModel\n",
    "from helical.models.scgpt.model import scGPT,scGPTConfig\n",
    "from helical.models.uce.model import UCE, UCEConfig\n",
    "from helical.models.uce.fine_tuning_model import UCEFineTuningModel\n",
    "import torch\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e652594b6df4aa8a7af3603ffaa8970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92961183fc2f4310bdfda25bd1f34b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/4.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d6bd32cfb54fe384c80bc99414310f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/553M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939106989f924ba9ab673b95da26daa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"helical-ai/yolksac_human\",trust_remote_code=True, download_mode=\"reuse_cache_if_exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_columns = [obs for obs in list(ds.features.keys()) if not obs == 'raw_counts']\n",
    "obs_data = pd.DataFrame(ds.select_columns(observation_columns).data.to_pandas(),columns=observation_columns)\n",
    "lil = lil_matrix((len(ds),ds[0]['size']))\n",
    "lil.data = np.array(ds['raw_counts'],dtype=\"object\")\n",
    "lil.rows = np.array(ds['rows'],dtype=\"object\")\n",
    "ann_data = ad.AnnData(lil.tocsr(),obs=obs_data)\n",
    "ann_data.var_names = ds.features['raw_counts'].id.split(\",\")\n",
    "ann_data.var['gene_name'] = ann_data.var_names.str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For this classification task we want to predict cell type classes\n",
    "- So we save the cell types as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CD4 T cells',\n",
       " 'CD4 T cells',\n",
       " 'CD14+ Monocytes',\n",
       " 'CD14+ Monocytes',\n",
       " 'CD8 T cells',\n",
       " 'CD4 T cells',\n",
       " 'CD14+ Monocytes',\n",
       " 'CD4 T cells',\n",
       " 'CD4 T cells',\n",
       " 'CD14+ Monocytes']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_types = list(np.array(ann_data.obs[\"LVL1\"].tolist()))\n",
    "cell_types[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We convert these string labels into unique integer classes for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 8, 5, 5, 2, 8, 5, 8, 8, 5]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_set = set(cell_types)\n",
    "class_id_dict = dict(zip(label_set, [i for i in range(len(label_set))]))\n",
    "\n",
    "for i in range(len(cell_types)):\n",
    "    cell_types[i] = class_id_dict[cell_types[i]]\n",
    "\n",
    "cell_types[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geneformer Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the desired pretrained Geneformer model and desired configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geneformer_config = GeneformerConfig(device=device, batch_size=5, model_name=\"gf-6L-30M-i2048\")\n",
    "geneformer = Geneformer(configurer = geneformer_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the data so it is in the correct form for Geneformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = geneformer.process_data(ann_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geneformer makes use of the Hugging Face dataset class and so we need to add the labels as a column to this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'length', 'cell_types'],\n",
       "    num_rows: 11990\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.add_column('cell_types', cell_types)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Geneformer Fine-Tuning Model from the Helical package which appends a fine-tuning head automatically from the list of available heads\n",
    "- Define the task type, which in this case is classification\n",
    "- Defined the output size, which is the number of unique labels for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "geneformer_fine_tune = GeneformerFineTuningModel(geneformer_model=geneformer, fine_tuning_head=\"classification\", output_size=len(label_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle and split our dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle()\n",
    "dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing the first 2 encoder layers of the Geneformer model during fine-tuning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d70a656590485cac5a2a0bbfd9ad03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fine-Tuning:   0%|          | 0/1919 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc4a078d75d4257992a36bde3758c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fine-Tuning Validation:   0%|          | 0/480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "geneformer_fine_tune.train(train_dataset=dataset[\"train\"], validation_dataset=dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scGPT Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the same procedure with scGPT\n",
    "- Loading the model and setting desired configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scgpt_config=scGPTConfig(batch_size=10, device=device)\n",
    "scgpt = scGPT(configurer=scgpt_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slightly different methodology for getting the dataset for scGPT since it does not make use of the Hugging Face Dataset class\n",
    "- Split the data into a train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = scgpt.process_data(ann_data[:int(len(ann_data)*0.8)])\n",
    "validation_dataset = scgpt.process_data(ann_data[int(len(ann_data)*0.8):int(len(ann_data))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for the cell type labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types = list(ann_data.obs.cell_type[:int(len(ann_data)*0.8)])\n",
    "val_cell_types = list(ann_data.obs.cell_type[int(len(ann_data)*0.8):int(len(ann_data))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert them into integer class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cell_types)):\n",
    "    cell_types[i] = class_id_dict[cell_types[i]]\n",
    "for i in range(len(val_cell_types)):\n",
    "    val_cell_types[i] = class_id_dict[val_cell_types[i]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the scGPT fine-tuning model with the desired head and number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scgpt_fine_tune = scGPTFineTuningModel(scGPT_model=scgpt, fine_tuning_head=\"classification\", output_size=len(label_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For scGPT fine tuning we have to pass in the labels as a separate list\n",
    "- This is the same for the validation and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning: epoch 1/1: 100%|██████████| 960/960 [00:54<00:00, 17.58it/s, loss=0.953]\n",
      "Fine-Tuning Validation: 100%|██████████| 240/240 [00:04<00:00, 57.46it/s, accuracy=0.902]\n"
     ]
    }
   ],
   "source": [
    "scgpt_fine_tune.train(train_input_data=dataset, train_labels=cell_types, validation_input_data=validation_dataset, validation_labels=val_cell_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UCE Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uce_config=UCEConfig(batch_size=5, device=device)\n",
    "uce = UCE(configurer=uce_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data the same way as for scGPT\n",
    "- Add names for each dataset, as datasets are stored as .npz files and separate files are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = uce.process_data(ann_data[:int(len(ann_data)*0.8)], name=\"train\")\n",
    "validation_dataset = uce.process_data(ann_data[int(len(ann_data)*0.8):int(len(ann_data))], name=\"validation\")\n",
    "\n",
    "cell_types = list(ann_data.obs.cell_type[:int(len(ann_data)*0.8)])\n",
    "val_cell_types = list(ann_data.obs.cell_type[int(len(ann_data)*0.8):int(len(ann_data))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class to integer conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cell_types)):\n",
    "    cell_types[i] = class_id_dict[cell_types[i]]\n",
    "for i in range(len(val_cell_types)):\n",
    "    val_cell_types[i] = class_id_dict[val_cell_types[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the fine-tuning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "uce_fine_tune = UCEFineTuningModel(uce_model=uce, fine_tuning_head=\"classification\", output_size=len(label_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning: epoch 1/1: 100%|██████████| 1919/1919 [04:59<00:00,  6.40it/s, loss=1.72]\n",
      "Fine-Tuning Validation: 100%|██████████| 480/480 [00:28<00:00, 16.67it/s, accuracy=0.412]\n"
     ]
    }
   ],
   "source": [
    "uce_fine_tune.train(train_input_data=dataset, train_labels=cell_types, validation_input_data=validation_dataset, validation_labels=val_cell_types)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helical-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
