{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification fine-tuning using Helical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell type classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helical.models.geneformer.geneformer_config import GeneformerConfig\n",
    "from helical.models.geneformer.fine_tuning_model import GeneformerFineTuningModel\n",
    "from helical.models.geneformer.model import Geneformer\n",
    "from helical.models.scgpt.fine_tuning_model import scGPTFineTuningModel\n",
    "from helical.models.scgpt.model import scGPT,scGPTConfig\n",
    "from helical.models.uce.model import UCE, UCEConfig\n",
    "from helical.models.uce.fine_tuning_model import UCEFineTuningModel\n",
    "import torch\n",
    "import anndata as ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 11990 × 12000\n",
       "    obs: 'n_counts', 'batch', 'labels', 'str_labels', 'cell_type'\n",
       "    var: 'gene_symbols', 'n_counts-0', 'n_counts-1', 'n_counts', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
       "    uns: 'cell_types', 'hvg'\n",
       "    obsm: 'design', 'normalized_qc', 'qc_pc', 'raw_qc'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_data = ad.read_h5ad(\"./10k_pbmcs_proc.h5ad\")\n",
    "ann_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For this classification task we want to predict cell type classes\n",
    "- So we save the cell types as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CD4 T cells',\n",
       " 'CD4 T cells',\n",
       " 'CD14+ Monocytes',\n",
       " 'CD14+ Monocytes',\n",
       " 'CD8 T cells',\n",
       " 'CD4 T cells',\n",
       " 'CD14+ Monocytes',\n",
       " 'CD4 T cells',\n",
       " 'CD4 T cells',\n",
       " 'CD14+ Monocytes']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_types = list(ann_data.obs.cell_type)\n",
    "cell_types[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We convert these string labels into unique integer classes for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 8, 5, 5, 2, 8, 5, 8, 8, 5]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_set = set(cell_types)\n",
    "class_id_dict = dict(zip(label_set, [i for i in range(len(label_set))]))\n",
    "\n",
    "for i in range(len(cell_types)):\n",
    "    cell_types[i] = class_id_dict[cell_types[i]]\n",
    "\n",
    "cell_types[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geneformer Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the desired pretrained Geneformer model and desired configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geneformer_config = GeneformerConfig(device=device, batch_size=5, model_name=\"gf-6L-30M-i2048\")\n",
    "geneformer = Geneformer(configurer = geneformer_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the data so it is in the correct form for Geneformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = geneformer.process_data(ann_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geneformer makes use of the Hugging Face dataset class and so we need to add the labels as a column to this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'length', 'cell_types'],\n",
       "    num_rows: 11990\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.add_column('cell_types', cell_types)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Geneformer Fine-Tuning Model from the Helical package which appends a fine-tuning head automatically from the list of available heads\n",
    "- Define the task type, which in this case is classification\n",
    "- Defined the output size, which is the number of unique labels for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "geneformer_fine_tune = GeneformerFineTuningModel(geneformer_model=geneformer, fine_tuning_head=\"classification\", output_size=len(label_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle and split our dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle()\n",
    "dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing the first 2 encoder layers of the Geneformer model during fine-tuning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d70a656590485cac5a2a0bbfd9ad03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fine-Tuning:   0%|          | 0/1919 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc4a078d75d4257992a36bde3758c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fine-Tuning Validation:   0%|          | 0/480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "geneformer_fine_tune.train(train_dataset=dataset[\"train\"], validation_dataset=dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scGPT Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the same procedure with scGPT\n",
    "- Loading the model and setting desired configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scgpt_config=scGPTConfig(batch_size=10, device=device)\n",
    "scgpt = scGPT(configurer=scgpt_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slightly different methodology for getting the dataset for scGPT since it does not make use of the Hugging Face Dataset class\n",
    "- Split the data into a train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = scgpt.process_data(ann_data[:int(len(ann_data)*0.8)])\n",
    "validation_dataset = scgpt.process_data(ann_data[int(len(ann_data)*0.8):int(len(ann_data))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for the cell type labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types = list(ann_data.obs.cell_type[:int(len(ann_data)*0.8)])\n",
    "val_cell_types = list(ann_data.obs.cell_type[int(len(ann_data)*0.8):int(len(ann_data))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert them into integer class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cell_types)):\n",
    "    cell_types[i] = class_id_dict[cell_types[i]]\n",
    "for i in range(len(val_cell_types)):\n",
    "    val_cell_types[i] = class_id_dict[val_cell_types[i]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the scGPT fine-tuning model with the desired head and number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scgpt_fine_tune = scGPTFineTuningModel(scGPT_model=scgpt, fine_tuning_head=\"classification\", output_size=len(label_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For scGPT fine tuning we have to pass in the labels as a separate list\n",
    "- This is the same for the validation and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning: epoch 1/1: 100%|██████████| 960/960 [00:54<00:00, 17.58it/s, loss=0.953]\n",
      "Fine-Tuning Validation: 100%|██████████| 240/240 [00:04<00:00, 57.46it/s, accuracy=0.902]\n"
     ]
    }
   ],
   "source": [
    "scgpt_fine_tune.train(train_input_data=dataset, train_labels=cell_types, validation_input_data=validation_dataset, validation_labels=val_cell_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UCE Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uce_config=UCEConfig(batch_size=5, device=device)\n",
    "uce = UCE(configurer=uce_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data the same way as for scGPT\n",
    "- Add names for each dataset, as datasets are stored as .npz files and separate files are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = uce.process_data(ann_data[:int(len(ann_data)*0.8)], name=\"train\")\n",
    "validation_dataset = uce.process_data(ann_data[int(len(ann_data)*0.8):int(len(ann_data))], name=\"validation\")\n",
    "\n",
    "cell_types = list(ann_data.obs.cell_type[:int(len(ann_data)*0.8)])\n",
    "val_cell_types = list(ann_data.obs.cell_type[int(len(ann_data)*0.8):int(len(ann_data))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class to integer conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cell_types)):\n",
    "    cell_types[i] = class_id_dict[cell_types[i]]\n",
    "for i in range(len(val_cell_types)):\n",
    "    val_cell_types[i] = class_id_dict[val_cell_types[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the fine-tuning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "uce_fine_tune = UCEFineTuningModel(uce_model=uce, fine_tuning_head=\"classification\", output_size=len(label_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning: epoch 1/1: 100%|██████████| 1919/1919 [04:59<00:00,  6.40it/s, loss=1.72]\n",
      "Fine-Tuning Validation: 100%|██████████| 480/480 [00:28<00:00, 16.67it/s, accuracy=0.412]\n"
     ]
    }
   ],
   "source": [
    "uce_fine_tune.train(train_input_data=dataset, train_labels=cell_types, validation_input_data=validation_dataset, validation_labels=val_cell_types)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helical-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
